{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynlp import preprocess, create_co_matrix, cos_similarity, most_similar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppmi 계산을 함수로 구현 \n",
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[i]*S[j]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset import ptb\n",
    "\n",
    "# corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "# print('말뭉치 크기:', len(corpus), corpus.shape)  # (929589,)\n",
    "# print('corpus[:30]:', corpus[:30])\n",
    "# print()\n",
    "# print('id_to_word[0]:', id_to_word[0])\n",
    "# print('id_to_word[1]:', id_to_word[1])\n",
    "# print('id_to_word[2]:', id_to_word[2])\n",
    "# print()\n",
    "# print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "# print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "# print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습과제 답안 구현 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [실습 과제]  : PPMI 단어의 유사도 측정\n",
    "\n",
    "# 1. 아래 문장에 사용된 단어를 PTB데이터셋을 PPMI 와 SVD 차원 축소 기법을 사용하여 만든 벡터에 넣어 각 단어들의 유사도를 측정하여 출력해보세요\n",
    "\n",
    "# text = \"The black cat ran so fast that the white mouse could not run away.\"\n",
    "\n",
    "# 주어진 text를 말뭉치로 변환한다\n",
    "# 마침표는 삭제한다\n",
    "# 유사도 출력 코드는 for 문을 사용하여 반복한다\n",
    "\n",
    "# 2. WordNet을 사용한 경로 거리 기반 유사도 (Path Distance Similarity)값과 비교하여 보세요\n",
    "# 'black'과 'white'의 유사도와 'cat'과 'mouse'의 유사도만 다음 3개의 방법으로 비교해 본다\n",
    "# - 경로 거리 기반 유사도 (Path Distance Similarity)\n",
    "# - 우 팔머 유사도 (Wu-Palmer Similarity)\n",
    "# - 리콕 초도로우 유사도(Leacock Chordorow Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wonseok\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in long_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Wonseok\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in log2\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% 완료\n",
      "2.0% 완료\n",
      "3.0% 완료\n",
      "4.0% 완료\n",
      "5.0% 완료\n",
      "6.0% 완료\n",
      "7.0% 완료\n",
      "8.0% 완료\n",
      "9.0% 완료\n",
      "10.0% 완료\n",
      "11.0% 완료\n",
      "12.0% 완료\n",
      "13.0% 완료\n",
      "14.0% 완료\n",
      "15.0% 완료\n",
      "16.0% 완료\n",
      "17.0% 완료\n",
      "18.0% 완료\n",
      "19.0% 완료\n",
      "20.0% 완료\n",
      "21.0% 완료\n",
      "22.0% 완료\n",
      "23.0% 완료\n",
      "24.0% 완료\n",
      "25.0% 완료\n",
      "26.0% 완료\n",
      "27.0% 완료\n",
      "28.0% 완료\n",
      "29.0% 완료\n",
      "30.0% 완료\n",
      "31.0% 완료\n",
      "32.0% 완료\n",
      "33.0% 완료\n",
      "34.0% 완료\n",
      "35.0% 완료\n",
      "36.0% 완료\n",
      "37.0% 완료\n",
      "38.0% 완료\n",
      "39.0% 완료\n",
      "40.0% 완료\n",
      "41.0% 완료\n",
      "42.0% 완료\n",
      "43.0% 완료\n",
      "44.0% 완료\n",
      "45.0% 완료\n",
      "46.0% 완료\n",
      "47.0% 완료\n",
      "48.0% 완료\n",
      "49.0% 완료\n",
      "50.0% 완료\n",
      "51.0% 완료\n",
      "52.0% 완료\n",
      "53.0% 완료\n",
      "54.0% 완료\n",
      "55.0% 완료\n",
      "56.0% 완료\n",
      "57.0% 완료\n",
      "58.0% 완료\n",
      "59.0% 완료\n",
      "60.0% 완료\n",
      "61.0% 완료\n",
      "62.0% 완료\n",
      "63.0% 완료\n",
      "64.0% 완료\n",
      "65.0% 완료\n",
      "66.0% 완료\n",
      "67.0% 완료\n",
      "68.0% 완료\n",
      "69.0% 완료\n",
      "70.0% 완료\n",
      "71.0% 완료\n",
      "72.0% 완료\n",
      "73.0% 완료\n",
      "74.0% 완료\n",
      "75.0% 완료\n",
      "76.0% 완료\n",
      "77.0% 완료\n",
      "78.0% 완료\n",
      "79.0% 완료\n",
      "80.0% 완료\n",
      "81.0% 완료\n",
      "82.0% 완료\n",
      "83.0% 완료\n",
      "84.0% 완료\n",
      "85.0% 완료\n",
      "86.0% 완료\n",
      "87.0% 완료\n",
      "88.0% 완료\n",
      "89.0% 완료\n",
      "90.0% 완료\n",
      "91.0% 완료\n",
      "92.0% 완료\n",
      "93.0% 완료\n",
      "94.0% 완료\n",
      "95.0% 완료\n",
      "96.0% 완료\n",
      "97.0% 완료\n",
      "98.0% 완료\n",
      "99.0% 완료\n",
      "100.0% 완료\n"
     ]
    }
   ],
   "source": [
    "# PTB 데이터셋으로 PPMI 얻기\n",
    "\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating SVD ...\n",
      "(10000, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.38250519e-12, -9.53826770e-07, -2.34474601e-06, ...,\n",
       "        -1.13648439e-05,  7.07858417e-05, -8.12277358e-05],\n",
       "       [-8.03852818e-12, -1.02774420e-08, -1.36924911e-07, ...,\n",
       "        -1.38340765e-05,  1.09310939e-04, -1.31357810e-04],\n",
       "       [-1.27229824e-11, -4.16941770e-09,  4.17888764e-08, ...,\n",
       "        -2.22208582e-05,  1.64593715e-04, -1.86716905e-04],\n",
       "       ...,\n",
       "       [ 4.42603324e-03, -6.48023514e-03,  1.14532383e-02, ...,\n",
       "        -1.17646912e-02, -2.72442517e-03,  6.51378697e-03],\n",
       "       [ 2.45890394e-03, -4.92048915e-03,  8.02483037e-03, ...,\n",
       "        -3.60710523e-03,  3.76736140e-03,  4.68394195e-04],\n",
       "       [ 3.88840283e-03, -7.84245878e-03,  8.07832833e-03, ...,\n",
       "         1.02159614e-03,  3.02083464e-03,  1.13881696e-02]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('calculating SVD ...')\n",
    "\n",
    "# truncated SVD : 속도가 빠르다, random 사용으로 매번 다른 결과 출력\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
    "                         random_state=None)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]  # 100개로 차원 축소\n",
    "print(word_vecs.shape) # (1000,100)\n",
    "word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  most_similar('she', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('was', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('much', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('scared', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('because', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('the', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('lion', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('was', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('too', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('big', word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'black',\n",
       " 'cat',\n",
       " 'ran',\n",
       " 'so',\n",
       " 'fast',\n",
       " 'that',\n",
       " 'the',\n",
       " 'white',\n",
       " 'mouse',\n",
       " 'could',\n",
       " 'not',\n",
       " 'run',\n",
       " 'away']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The black cat ran so fast that the white mouse could not run away.'\n",
    "text = text.lower()\n",
    "text = text.replace('.', '')\n",
    "words = text.split(' ')\n",
    "\n",
    "# corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] the\n",
      " of: 0.691506028175354\n",
      " a: 0.63596510887146\n",
      " in: 0.5060994625091553\n",
      " on: 0.4945952296257019\n",
      " this: 0.4507043957710266\n",
      "\n",
      "[query] black\n",
      " women: 0.606795072555542\n",
      " hispanic: 0.5883038640022278\n",
      " young: 0.5459905862808228\n",
      " white: 0.5185385942459106\n",
      " smoke: 0.5137501358985901\n",
      "\n",
      "[query] cat\n",
      " holidays: 0.6122410297393799\n",
      " bars: 0.5586532950401306\n",
      " kuala: 0.5268138647079468\n",
      " 1920s: 0.5177140235900879\n",
      " corresponding: 0.5062284469604492\n",
      "\n",
      "[query] ran\n",
      " throws: 0.528727650642395\n",
      " pumped: 0.5122578740119934\n",
      " topiary: 0.49728912115097046\n",
      " enters: 0.49525368213653564\n",
      " marched: 0.49137941002845764\n",
      "\n",
      "[query] so\n",
      " too: 0.595352292060852\n",
      " more: 0.509425163269043\n",
      " far: 0.49367755651474\n",
      " cheap: 0.4416796863079071\n",
      " very: 0.4212384521961212\n",
      "\n",
      "[query] fast\n",
      " twice: 0.46480420231819153\n",
      " quickly: 0.4545675814151764\n",
      " surprisingly: 0.4422934651374817\n",
      " accessible: 0.43461841344833374\n",
      " hard: 0.4161495864391327\n",
      "\n",
      "[query] that\n",
      " he: 0.5293017625808716\n",
      " it: 0.5105709433555603\n",
      " there: 0.42958012223243713\n",
      " but: 0.42865893244743347\n",
      " they: 0.4277789294719696\n",
      "\n",
      "[query] the\n",
      " of: 0.691506028175354\n",
      " a: 0.63596510887146\n",
      " in: 0.5060994625091553\n",
      " on: 0.4945952296257019\n",
      " this: 0.4507043957710266\n",
      "\n",
      "[query] white\n",
      " black: 0.5185385942459106\n",
      " males: 0.4863411486148834\n",
      " red: 0.46187639236450195\n",
      " house: 0.4506610929965973\n",
      " young: 0.4387904703617096\n",
      "\n",
      "[query] mouse\n",
      " motive: 0.5841702818870544\n",
      " fuels: 0.5547130703926086\n",
      " cnbc: 0.5491454005241394\n",
      " stimulators: 0.5282564163208008\n",
      " script: 0.5031645894050598\n",
      "\n",
      "[query] could\n",
      " would: 0.5471222996711731\n",
      " wo: 0.4864790439605713\n",
      " will: 0.44395512342453003\n",
      " may: 0.43712612986564636\n",
      " ca: 0.41018733382225037\n",
      "\n",
      "[query] not\n",
      " n't: 0.5833935141563416\n",
      " does: 0.5294781923294067\n",
      " do: 0.4707008898258209\n",
      " did: 0.4641205668449402\n",
      " only: 0.36872613430023193\n",
      "\n",
      "[query] run\n",
      " tv: 0.4083075225353241\n",
      " broadcast: 0.4049384295940399\n",
      " campaign: 0.3876194655895233\n",
      " entertainment: 0.3855331838130951\n",
      " simultaneously: 0.37250563502311707\n",
      "\n",
      "[query] away\n",
      " out: 0.5642987489700317\n",
      " off: 0.47599589824676514\n",
      " back: 0.4702839255332947\n",
      " down: 0.4027262032032013\n",
      " up: 0.40125665068626404\n"
     ]
    }
   ],
   "source": [
    "for query in words:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 과제 2번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black: [path] 0.08333333333333333\n",
      "black: [wup] 0.15384615384615385\n",
      "black: [lch] 1.1526795099383855\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# syn = wordnet.synsets('black')\n",
    "# print(syn)\n",
    "black = wordnet.synset('black.n.01')\n",
    "white = wordnet.synset('white.n.01')\n",
    "\n",
    "# 경로 유사도\n",
    "print('black: [path]', black.path_similarity(white))\n",
    "\n",
    "# Wu-Palmer Similarit\n",
    "print('black: [wup]', black.wup_similarity(white))\n",
    "\n",
    "# Leacock Chordorow Similarity\n",
    "print('black: [lch]', black.lch_similarity(white))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: [path] 0.05\n",
      "cat: [wup] 0.09523809523809523\n",
      "cat: [lch] 0.6418538861723948\n"
     ]
    }
   ],
   "source": [
    "# syn = wordnet.synsets('cat')\n",
    "# print(syn)\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "mouse = wordnet.synset('mouse.n.01')\n",
    "\n",
    "# 경로 유사도\n",
    "print('cat: [path]', black.path_similarity(mouse))\n",
    "\n",
    "# Wu-Palmer Similarit\n",
    "print('cat: [wup]', black.wup_similarity(mouse))\n",
    "\n",
    "# Leacock Chordorow Similarity\n",
    "print('cat: [lch]', black.lch_similarity(mouse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "black - white [path] : 0.083333\n",
      "black - white [wup] : 0.15384615384615385\n",
      "black - white [lch] : 1.1526795099383855\n",
      "--------------------------------------------------\n",
      "cat - mouse [path] : 0.166667\n",
      "cat - mouse [wup] : 0.8148148148148148\n",
      "cat - mouse [lch] : 1.845826690498331\n",
      "--------------------------------------------------\n",
      "fast - run [path] : 0.083333\n",
      "fast - run [wup] : 0.47619047619047616\n",
      "fast - run [lch] : 1.1526795099383855\n"
     ]
    }
   ],
   "source": [
    "#  정규표현식 사용 자동화 구현\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# 표제어를 정규표현식으로 검출\n",
    "def get_match(word) :\n",
    "    # r = r\"black.n.01\"\n",
    "    r = r\"^(%s)+(.)([a-z]+)(.)(01)$\"%word\n",
    "    p = re.compile(r, re.I)\n",
    "\n",
    "    syn = [ syn.name() for syn in wordnet.synsets(word) ]\n",
    "    # print(syn) \n",
    "\n",
    "    for s in syn:\n",
    "        # print(s)\n",
    "        match = p.match(s,0)\n",
    "        if match :\n",
    "            #print(match.group())\n",
    "            break\n",
    "    if match.group():\n",
    "        return match.group()\n",
    "\n",
    "# 검출된 두 단어의 표제어로 유사도 출력\n",
    "def get_wordnet_similarity(word1,word2):\n",
    "    \n",
    "    word1_match = get_match(word1)\n",
    "    word2_match = get_match(word2)\n",
    "\n",
    "    word1_syn = wordnet.synset(word1_match)\n",
    "    word2_syn = wordnet.synset(word2_match)\n",
    "    print('-'*50)\n",
    "\n",
    "    # 경로 유사도\n",
    "    print('%s - %s [path] : %f'%(word1,word2, word1_syn.path_similarity(word2_syn)))\n",
    "    \n",
    "    # Wu-Palmer Similarity\n",
    "    print('%s - %s [wup] :'%(word1,word2), word1_syn.wup_similarity(word2_syn))\n",
    "\n",
    "    # Leacock Chordorow Similarity\n",
    "    print('%s - %s [lch] :'%(word1,word2), word1_syn.lch_similarity(word2_syn))\n",
    "\n",
    "\n",
    "# 함수 호출   \n",
    "get_wordnet_similarity('black', 'white')\n",
    "get_wordnet_similarity('cat', 'mouse')\n",
    "get_wordnet_similarity('fast', 'run')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
