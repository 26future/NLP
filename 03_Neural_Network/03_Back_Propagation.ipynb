{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]] (1, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]\n",
      " [0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]\n",
      " [0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]\n",
      " [0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]\n",
      " [0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]\n",
      " [0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]\n",
      " [0.33827315 0.39762466 0.62439778 0.94366595 0.78599564 0.78234857\n",
      "  0.6240581  0.71067929]] (7, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 순전파\n",
    "\n",
    "D = 8\n",
    "N = 7\n",
    "x = np.random.rand(1,D)  # (1,8)\n",
    "# x = np.random.rand(D,).reshape(1,-1)  # (1,8)\n",
    "print(x, x.shape)\n",
    "print('-'*70)\n",
    "\n",
    "y = np.repeat(x,N,axis=0)  # 수직(행) 방향, axis=0\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0729196  0.06227804 0.0877057  0.0749236  0.21926435 0.9894172\n",
      "  0.92923984 0.86431945]\n",
      " [0.00943409 0.92786936 0.84714286 0.13099146 0.62095059 0.85730336\n",
      "  0.79013    0.59945452]\n",
      " [0.41990977 0.03833323 0.82462754 0.36102424 0.74108445 0.97786397\n",
      "  0.1275924  0.57399758]\n",
      " [0.63767158 0.7691092  0.98940996 0.61777463 0.68729127 0.32145559\n",
      "  0.76052393 0.44889394]\n",
      " [0.95970009 0.40227626 0.27860587 0.39592831 0.82657346 0.93107671\n",
      "  0.79948917 0.10668866]\n",
      " [0.68990679 0.80185906 0.40246878 0.60572179 0.04218371 0.01030179\n",
      "  0.35633794 0.71116097]\n",
      " [0.30160655 0.6893462  0.02932221 0.63319891 0.4449267  0.08442664\n",
      "  0.41922718 0.83708208]] (7, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[3.09114848 3.69107135 3.45928292 2.81956294 3.58227452 4.17184526\n",
      "  4.18254047 4.14159719]] (1, 8)\n"
     ]
    }
   ],
   "source": [
    "# 역전파 : sum\n",
    "dy = np.random.rand(N,D)\n",
    "print(dy, dy.shape)  # (7, 8)\n",
    "print('-'*70)\n",
    "dx = np.sum(dy,axis=0,keepdims=True)  # 수직 방향 합, keepdims=True이면 2차원, Flase이면 1차원\n",
    "print(dx, dx.shape)  # (1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67243912 0.09711838 0.5240633  0.54970958 0.73015161 0.45373492\n",
      "  0.54622644 0.19808965]\n",
      " [0.23131644 0.66480449 0.64466497 0.4268541  0.41595261 0.90694265\n",
      "  0.80658622 0.45837701]\n",
      " [0.68289642 0.77287084 0.959434   0.90458874 0.59106809 0.68937787\n",
      "  0.92458097 0.33080423]\n",
      " [0.94386712 0.10358962 0.83933465 0.4965158  0.65101754 0.13149328\n",
      "  0.00586308 0.07049283]\n",
      " [0.47092303 0.14956824 0.22293084 0.26735238 0.68918458 0.30238256\n",
      "  0.88531704 0.44920073]\n",
      " [0.61698889 0.67782474 0.18173931 0.77591969 0.27134685 0.58027324\n",
      "  0.67052087 0.13506767]\n",
      " [0.76666546 0.76218478 0.62251602 0.47490037 0.78090166 0.54140128\n",
      "  0.74299205 0.73722427]] (7, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[4.38509647 3.2279611  3.9946831  3.89584066 4.12962294 3.60560579\n",
      "  4.58208667 2.37925637]] (1, 8)\n"
     ]
    }
   ],
   "source": [
    "# 순전파\n",
    "\n",
    "D,N = 8,7\n",
    "x = np.random.rand(N,D)\n",
    "print(x, x.shape)  # (7, 8)\n",
    "print('-'*70)\n",
    "\n",
    "y = np.sum(x,axis=0,keepdims=True)  # 수직 방향 합, keepdims=True이면 2차원, Flase이면 1차원\n",
    "print(y, y.shape)  # (1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]] (1, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]\n",
      " [0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]\n",
      " [0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]\n",
      " [0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]\n",
      " [0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]\n",
      " [0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]\n",
      " [0.87020186 0.19942159 0.26475283 0.87328178 0.95324739 0.26596858\n",
      "  0.40674157 0.00430925]] (7, 8)\n"
     ]
    }
   ],
   "source": [
    "# 역전파\n",
    "\n",
    "dy = np.random.rand(1,D)  # (1,8)\n",
    "print(dy, dy.shape)\n",
    "print('-'*70)\n",
    "\n",
    "dx = np.repeat(dy,N,axis=0)  # 수직(행) 방향, axis=0\n",
    "print(dx, dx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatMul Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self,W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        W = self.params\n",
    "        out = np.dot(x,W)\n",
    "        self.x = x\n",
    "        return out\n",
    "        \n",
    "    def backward(self,dout):\n",
    "        W = self.params\n",
    "        dx = np.dot(dout,W.T)\n",
    "        dw = np.dot(self.x.T,dout)\n",
    "        self.grads[0][...] = dw  # 깊은 복사\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x1257dcac670 0x1257dcb2d50\n",
      "[4 5 6]\n",
      "0x1257dcb2d50 0x1257dcb2d50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "print(hex(id(a)),hex(id(b)))\n",
    "a = b    # 얕은 복사\n",
    "print(a)\n",
    "print(hex(id(a)),hex(id(b)))\n",
    "id(a) == id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n",
      "0x1257dd12f80 0x1257dd12f30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "a[...] = b  # 깊은 복사\n",
    "print(a)\n",
    "print(hex(id(a)),hex(id(b)))\n",
    "id(a) == id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.zeros_like\n",
    "a = np.arange(12).reshape(3,4)\n",
    "b = np.zeros_like(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [],[]\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = 1/(1+np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = dout*self.out*(1-self.out)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine 계층 : MatMul 노드에 bias를 더한 계층,  X*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self,W):\n",
    "        self.params = [W,b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x,W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "        \n",
    "    def backward(self,dout):\n",
    "        W, b = self.params\n",
    "        dx = np.dot(dout,W.T)\n",
    "        dw = np.dot(self.x.T,dout)\n",
    "        db = np.sum(dout,axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dw  # deep copy\n",
    "        self.grads[1][...] = db\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax with Loss 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [],[]\n",
    "        self.y = None  # softmax의 출력값\n",
    "        self.t = None  # 정답 레이블\n",
    "        \n",
    "    def softmax(self,x):\n",
    "        if x.ndim == 2:\n",
    "            x = x-x.max(axis=1, keepdims=True)  # nan출력을 방지\n",
    "            x = np.exp(x)\n",
    "            x /= x.sum(axis=1, keepdims=True)\n",
    "        elif x.dim == 1:\n",
    "            x = x-np.max(x)\n",
    "            x = np.exp(x)/np.sum(np.exp(x))\n",
    "        return x\n",
    "    \n",
    "# https://smile2x.tistory.com/entry/softmax-crossentropy-%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC \n",
    "    def cross_entropy_error(self,y,t):  \n",
    "        if y.ndim == 1:\n",
    "            t = t.reshape(1, t.size)\n",
    "            y = y.reshape(1, y.size)\n",
    "\n",
    "        # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\n",
    "        if t.size == y.size:\n",
    "            t = t.argmax(axis=1)\n",
    "\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size  # 1e-7은 log(0)으로 무한대가 나오는걸 방지\n",
    "\n",
    "    def forward(self,x,t):\n",
    "        self.t = t\n",
    "        self.y = self.softmax(x)\n",
    "        \n",
    "        # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\n",
    "        if t.size == y.size:\n",
    "            t = t.argmax(axis=1)\n",
    "        \n",
    "        loss = self.cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        \n",
    "        # dx = (self.y-self.t)/batch_size  # 순수 Softmax 계층일 경우\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inf inf inf]\n",
      "[nan nan nan]\n",
      "[  0 -10 -20]\n",
      "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wonseok\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# softmax 구현시에  지수값이 크면 overflow 발생으로 nan이 나오는 것을 방지하기 위해 입력 값의 최대값을 빼주어 사용한다\n",
    "a = np.array([1010,1000,990])\n",
    "print(np.exp(a))    # [inf inf inf]  , 무한대 값, 오버플로우 발생\n",
    "x = np.exp(a)/np.sum(np.exp(a))\n",
    "print(x)  # [nan nan nan]\n",
    "\n",
    "c = np.max(a)\n",
    "print(a - c)\n",
    "x2 = np.exp(a - c)/np.sum(np.exp(a - c))\n",
    "print(x2)  # [9.99954600e-01 4.53978686e-05 2.06106005e-09]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률적 경사하강법(Stochastic Gradient Descent)\n",
    "class SGD:\n",
    "    def __init__(self,lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr*grads[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    '''\n",
    "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "                self.v.append(np.zeros_like(param))\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
    "            \n",
    "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)\n",
    "            \n",
    "# https://dalpo0814.tistory.com/29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
